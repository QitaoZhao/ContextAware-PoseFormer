title: "human36m_vol_softmax_single"
kind: "human36m"
# logdir: "logs/ConPose@08.04.2023-00:50:04/checkpoints"
azureroot: ""
batch_output: true
vis_freq: 1000
vis_n_elements: 10

model:
  name: "vol"
  kind: "mpii"
  
  # image_shape: [288, 384]
  image_shape: [192, 256]
  heatmap_shape: [72, 96]
  heatmap_softmax: true
  heatmap_multiplier: 100.0

  init_weights: false
  # checkpoint: "logs/ConPose@08.04.2023-00:50:04/checkpoints/best_epoch.bin"
  checkpoint: ""

  backbone:
    name: "resnet152"
    style: "simple"

    num_final_layer_channel: 17
    num_joints: 17
    num_layers: 152
    
    init_weights: true
    fix_weights: true
    checkpoint: "data/pretrained/coco/pose_hrnet_w32_256x192.pth"
    # checkpoint: "data/pretrained/imagenet/hrnet_w32-36af842e.pth"
    # checkpoint: "data/pretrained/imagenet/hrnet_w48-8ef0771d.pth"
    # checkpoint: "data/pretrained/coco/pose_resnet_50_256x192.pth"
    # checkpoint: "data/pretrained/imagenet/resnet50-19c8e357.pth"
    # checkpoint: "data/pretrained/coco/CPN50_256x192.pth.tar"
    # checkpoint: "data/pretrained/coco/CPN50_384x288.pth.tar"
    
  volume_net:
    volume_aggregation_method: "softmax"
    use_gt_pelvis: false

    cuboid_size: 2500.0
    volume_size: 64
    volume_multiplier: 1.0
    volume_softmax: true

    use_feature_v2v: true

    temperature: 1500

  poseformer:
    embed_dim_ratio: 128
    depth: 4

loss:
  criterion: "MPJPE"
  scale_keypoints_3d: 0.1

  use_volumetric_ce_loss: true
  volumetric_ce_loss_weight: 0.01

  use_global_attention_loss: True
  global_attention_loss_weight: 1000000

dataset:
  kind: "human36m"
  data_format: ""
  # root: "data/human36m/processed"
  root: "../H36M-Toolbox/images/"
  extra_root: "data/human36m/extra"
  train_labels_path: "data/h36m_train.pkl"
  val_labels_path: "data/h36m_validation.pkl"
  
train:
  n_objects_per_epoch: 15000
  n_epochs: 9999

  batch_size: 512  # 512 for other backbones, 256 for cpn

  optimizer: 'Adam'
  backbone_lr: 0.0001
  backbone_lr_step: [1000]
  backbone_lr_factor: 0.1
  process_features_lr: 0.001
  volume_net_lr: 0.0064  # 0.0032 for cpn
  volume_net_lr_decay: 0.99
  volume_net_lr_step: [1000]
  volume_net_lr_factor: 0.5

  with_damaged_actions: true
  undistort_images: true

  scale_bbox: 1.0

  shuffle: true
  randomize_n_views: true
  min_n_views: 1
  max_n_views: 1
  num_workers: 14

  limb_length_path: "data/human36m/extra/mean_and_std_limb_length.h5"
  pred_results_path: "data/pretrained/human36m/human36m_alg_10-04-2019/checkpoints/0060/results/train.pkl"

val:
  batch_size: 512  # 512 for fixed backbone, 256 for cpn

  flip_test: true
  with_damaged_actions: true
  undistort_images: true

  scale_bbox: 1.0

  shuffle: false
  randomize_n_views: true
  min_n_views: 1
  max_n_views: 1
  num_workers: 14
  retain_every_n_frames_in_test: 1

  limb_length_path: "data/human36m/extra/mean_and_std_limb_length.h5"
  pred_results_path: "data/pretrained/human36m/human36m_alg_10-04-2019/checkpoints/0060/results/val.pkl"